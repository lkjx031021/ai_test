{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e7a332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user sent \"Hello, world!\" which is a common greeting. I need to respond appropriately. Since it\\'s a simple message, I should acknowledge it and maybe ask how I can assist them. I should keep the response friendly and open-ended. Let me make sure there\\'s no hidden request here. Just a greeting, so a standard reply should work. I\\'ll say something like \"Hello! How can I assist you today?\" That\\'s polite and invites them to ask more questions.\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-06-26T15:40:19.94083518Z', 'done': True, 'done_reason': 'stop', 'total_duration': 924790239, 'load_duration': 9606972, 'prompt_eval_count': 12, 'prompt_eval_duration': 13160983, 'eval_count': 114, 'eval_duration': 901710719, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run--fc462e8b-a57e-425e-8938-9a9a23bfc5dc-0', usage_metadata={'input_tokens': 12, 'output_tokens': 114, 'total_tokens': 126})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict, Optional\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:4b\")\n",
    "\n",
    "message = [HumanMessage(content=\"Hello, world!\")]\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 3,
>>>>>>> 429f32242ae0543b4754231b18942ff66c96f81b
   "id": "573b6e5d",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "NameError",
     "evalue": "name 'BaseModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[34;01muserinfo\u001b[39;00m(\u001b[43mBaseModel\u001b[49m):\n\u001b[32m      2\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33mThe name of the user\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mid\u001b[39m: \u001b[38;5;28mstr\u001b[39m = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33mThe id of the user, 身份证号\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'BaseModel' is not defined"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Qwen' id='qwen-001' phone=None introduction=None\n"
>>>>>>> 429f32242ae0543b4754231b18942ff66c96f81b
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class userinfo(BaseModel):\n",
    "    name: str = Field(..., description=\"The name of the user\")\n",
    "    id: str = Field(..., description=\"The id of the user, 身份证号\")\n",
    "    phone: Optional[str] = Field(None, description=\"The phone number of the user\")\n",
    "    introduction: Optional[str] = Field(None, description=\"A brief introduction of the user\")\n",
    "\n",
    "\n",
    "structurt = llm.with_structured_output(userinfo)\n",
    "\n",
    "# answer = structurt.invoke(\"My name is John Doe, my id is 123456789012345678, my phone number is 123-456-7890, and I am a software engineer.\")\n",
    "answer = structurt.invoke(\"what's your name?\")\n",
    "\n",
    "\n",
    "class input_state(TypedDict):\n",
    "    mm: Annotated[list[str], add_messages]\n",
    "    # mm: int\n",
    "\n",
    "\n",
    "def node_a(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    print(input)\n",
    "    x = input[\"mm\"][-1]\n",
    "    return {\"mm\": ['10']}\n",
    "\n",
    "def node_b(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    x = input[\"mm\"][-1]\n",
    "    print(input)\n",
    "    return {\"mm\": ['84']}\n",
    "\n",
    "graph = StateGraph(input_state)\n",
    "\n",
    "graph.add_node(\"node_a\", node_a)\n",
    "graph.add_node(\"node_b\", node_b)\n",
    "\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_edge(\"node_a\", \"node_b\")\n",
    "graph.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "# answer = graph.invoke({'mm': ['23']})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13990ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='曼波、曼波', additional_kwargs={}, response_metadata={}, id='94c0cd56-3b61-4917-9042-53a979eb7c55'), SystemMessage(content='你是一位网络梗专家，专门帮忙解答网络梗相关的问题。', additional_kwargs={}, response_metadata={}, id='61a02f7b-aac0-4c86-82e2-27ec7a8e8daf'), {'role': 'user', 'content': '对于所有回答要翻译成英文、中文、日语三种语言'}]\n",
      "{'mm': [HumanMessage(content='曼波、曼波', additional_kwargs={}, response_metadata={}, id='94c0cd56-3b61-4917-9042-53a979eb7c55'), SystemMessage(content='你是一位网络梗专家，专门帮忙解答网络梗相关的问题。', additional_kwargs={}, response_metadata={}, id='61a02f7b-aac0-4c86-82e2-27ec7a8e8daf'), AIMessage(content='<think>\\n好的，用户现在让我翻译成英文、中文、日语三种语言。首先，我需要确定用户提到的“曼波”具体指的是什么。曼波可能是指舞蹈，比如曼波舞（Mambo），或者是一个网络用语，可能和某个流行文化有关。\\n\\n用户之前提到过曼波，可能是在讨论舞蹈或者某个梗。我需要确认曼波的正确翻译和对应的含义。比如，在英语中，Mambo 是一种拉丁舞蹈，而日语中通常也使用“マンボ”来表示。中文的话，直接用“曼波”或者“曼波舞”比较合适。\\n\\n接下来，我需要确保翻译准确，同时符合网络用语的常见表达。可能用户希望了解曼波在不同语言中的表达方式，或者想确认某个特定的梗。另外，用户可能在测试我的翻译能力，或者想确认某个术语的正确性。\\n\\n另外，用户可能没有明确说明，但可能需要更多的上下文。比如，曼波是否与某个事件、人物或流行文化有关？如果没有，可能需要给出基本的翻译和解释，同时保持简洁。\\n\\n最后，确保回答符合用户的要求，三种语言都准确无误，并且自然流畅。可能需要检查每个语言的拼写和术语是否正确，比如日语中的“マンボ”是否正确，或者是否有其他常用表达。\\n</think>\\n\\n**English:** Mambo, Mambo  \\n**Chinese:** 曼波，曼波  \\n**Japanese:** マンボ、マンボ  \\n\\n（注：曼波通常指拉丁舞蹈Mambo，或网络中可能指代特定梗，此处按通用翻译处理。）', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-06-25T13:49:29.394989665Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2793866087, 'load_duration': 10002274, 'prompt_eval_count': 51, 'prompt_eval_duration': 10835455, 'eval_count': 347, 'eval_duration': 2767872658, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run--c28c1896-2d04-49ed-b8e9-33d795d3584b-0', usage_metadata={'input_tokens': 51, 'output_tokens': 347, 'total_tokens': 398})]}\n",
      "<think>\n",
      "好的，用户现在让我翻译成英文、中文、日语三种语言。首先，我需要确定用户提到的“曼波”具体指的是什么。曼波可能是指舞蹈，比如曼波舞（Mambo），或者是一个网络用语，可能和某个流行文化有关。\n",
      "\n",
      "用户之前提到过曼波，可能是在讨论舞蹈或者某个梗。我需要确认曼波的正确翻译和对应的含义。比如，在英语中，Mambo 是一种拉丁舞蹈，而日语中通常也使用“マンボ”来表示。中文的话，直接用“曼波”或者“曼波舞”比较合适。\n",
      "\n",
      "接下来，我需要确保翻译准确，同时符合网络用语的常见表达。可能用户希望了解曼波在不同语言中的表达方式，或者想确认某个特定的梗。另外，用户可能在测试我的翻译能力，或者想确认某个术语的正确性。\n",
      "\n",
      "另外，用户可能没有明确说明，但可能需要更多的上下文。比如，曼波是否与某个事件、人物或流行文化有关？如果没有，可能需要给出基本的翻译和解释，同时保持简洁。\n",
      "\n",
      "最后，确保回答符合用户的要求，三种语言都准确无误，并且自然流畅。可能需要检查每个语言的拼写和术语是否正确，比如日语中的“マンボ”是否正确，或者是否有其他常用表达。\n",
      "</think>\n",
      "\n",
      "**English:** Mambo, Mambo  \n",
      "**Chinese:** 曼波，曼波  \n",
      "**Japanese:** マンボ、マンボ  \n",
      "\n",
      "（注：曼波通常指拉丁舞蹈Mambo，或网络中可能指代特定梗，此处按通用翻译处理。）\n"
     ]
    }
   ],
   "source": [
    "class input_state(TypedDict):\n",
    "    mm: Annotated[list[AnyMessage], add_messages]\n",
    "    # mm: int\n",
    "\n",
    "\n",
    "def node_a(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    prompt = \"你是一位网络梗专家，专门帮忙解答网络梗相关的问题。\"\n",
    "    message = [{\"role\": \"system\", \"content\": prompt}]\n",
    "    return {\"mm\": message}\n",
    "\n",
    "def node_b(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    messages = input[\"mm\"] + [{\"role\": \"user\", \"content\": \"对于所有回答要翻译成英文、中文、日语三种语言\"}]\n",
    "    answer = llm.invoke(messages)\n",
    "    print(messages)\n",
    "\n",
    "    return {\"mm\": answer}\n",
    "\n",
    "graph = StateGraph(input_state)\n",
    "\n",
    "graph.add_node(\"node_a\", node_a)\n",
    "graph.add_node(\"node_b\", node_b)\n",
    "\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_edge(\"node_a\", \"node_b\")\n",
    "graph.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "answer = graph.invoke({\"mm\": [HumanMessage(content=\"曼波、曼波\")]})\n",
    "print(answer)\n",
    "print(answer[\"mm\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd43f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'x': 2}]}\n",
      "in: node_b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'x': 2}, {'x': 4}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from typing import Annotated\n",
    "import operator\n",
    "from langgraph.graph import START, END, StateGraph, add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    messages: Annotated[list[str], operator.add]\n",
    "\n",
    "# class InputState(dict):\n",
    "#     ...\n",
    "\n",
    "def node_a(input: InputState):\n",
    "    mm = input[\"messages\"][-1][\"x\"]\n",
    "    print('in: node_a')\n",
    "    return {\"messages\": [{\"x\": mm + 1}]}\n",
    "\n",
    "def node_b(input: InputState):\n",
    "    mm = input[\"messages\"][-1][\"x\"]\n",
    "    print('in: node_b')\n",
    "    return {\"messages\": [{\"x\": mm + 2}]}\n",
    "\n",
    "def condition(input: InputState):\n",
    "    print(input)\n",
    "    mm = input[\"messages\"][-1][\"x\"]\n",
    "    if mm // 2 == 0:\n",
    "        return \"node_a\"\n",
    "    else:\n",
    "        return \"node_b\"\n",
    "\n",
    "graph = StateGraph(InputState)\n",
    "\n",
    "graph.add_node(\"node_a\", node_a)\n",
    "graph.add_node(\"node_b\", node_b)\n",
    "# graph.add_node(\"condition\", condition)\n",
    "\n",
    "# graph.add_edge(START, \"condition\")\n",
    "graph.add_conditional_edges(START, condition, )\n",
    "graph.set_finish_point(\"node_a\")\n",
    "graph.set_finish_point(\"node_b\")\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [{\"x\":2}]})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
