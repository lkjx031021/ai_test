{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e7a332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user sent \"Hello, world!\" which is a common greeting. I need to respond appropriately. Since it\\'s a simple message, I should acknowledge it and maybe add a friendly reply. Let me check if there\\'s any specific context I\\'m missing. No, it\\'s just a greeting. I\\'ll respond with a cheerful message to keep the conversation going. Maybe something like \"Hello! How can I assist you today?\" That sounds good. It\\'s polite and opens the door for further interaction. I should make sure to keep it friendly and welcoming. Alright, that\\'s ready to send.\\n</think>\\n\\nHello! How can I assist you today? 😊', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-06-22T11:48:32.707954634Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3191429614, 'load_duration': 1951281808, 'prompt_eval_count': 12, 'prompt_eval_duration': 151085840, 'eval_count': 137, 'eval_duration': 1088446800, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run--c179f0de-d6ce-4e78-ba75-74376389b482-0', usage_metadata={'input_tokens': 12, 'output_tokens': 137, 'total_tokens': 149})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict, Optional\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:4b\")\n",
    "\n",
    "message = [HumanMessage(content=\"Hello, world!\")]\n",
    "\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "573b6e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mm': [HumanMessage(content='23', additional_kwargs={}, response_metadata={}, id='c1e24fa3-124a-4084-bc63-1685e6ae6b83')]}\n",
      "{'mm': [HumanMessage(content='23', additional_kwargs={}, response_metadata={}, id='c1e24fa3-124a-4084-bc63-1685e6ae6b83'), HumanMessage(content='10', additional_kwargs={}, response_metadata={}, id='8877211c-aa01-4778-b831-628b4b7c3523')]}\n",
      "{'mm': [HumanMessage(content='23', additional_kwargs={}, response_metadata={}, id='c1e24fa3-124a-4084-bc63-1685e6ae6b83'), HumanMessage(content='10', additional_kwargs={}, response_metadata={}, id='8877211c-aa01-4778-b831-628b4b7c3523'), HumanMessage(content='84', additional_kwargs={}, response_metadata={}, id='32861bd6-ac86-4147-a5e4-51e5f40e1877')]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class userinfo(BaseModel):\n",
    "    name: str = Field(..., description=\"The name of the user\")\n",
    "    id: str = Field(..., description=\"The id of the user, 身份证号\")\n",
    "    phone: Optional[str] = Field(None, description=\"The phone number of the user\")\n",
    "    introduction: Optional[str] = Field(None, description=\"A brief introduction of the user\")\n",
    "\n",
    "\n",
    "structurt = llm.with_structured_output(userinfo)\n",
    "\n",
    "# answer = structurt.invoke(\"My name is John Doe, my id is 123456789012345678, my phone number is 123-456-7890, and I am a software engineer.\")\n",
    "\n",
    "\n",
    "class input_state(TypedDict):\n",
    "    mm: Annotated[list[str], add_messages]\n",
    "    # mm: int\n",
    "\n",
    "\n",
    "def node_a(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    print(input)\n",
    "    x = input[\"mm\"][-1]\n",
    "    return {\"mm\": ['10']}\n",
    "\n",
    "def node_b(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    x = input[\"mm\"][-1]\n",
    "    print(input)\n",
    "    return {\"mm\": ['84']}\n",
    "\n",
    "graph = StateGraph(input_state)\n",
    "\n",
    "graph.add_node(\"node_a\", node_a)\n",
    "graph.add_node(\"node_b\", node_b)\n",
    "\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_edge(\"node_a\", \"node_b\")\n",
    "graph.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "answer = graph.invoke({'mm': ['23']})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13990ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='曼波、曼波', additional_kwargs={}, response_metadata={}, id='b835ee54-e0cb-4a50-a781-4bee4fe88a5d'), SystemMessage(content='你是一位网络梗专家，专门帮忙解答网络梗相关的问题。', additional_kwargs={}, response_metadata={}, id='a423b4be-0cf0-4b80-9b39-35b1334161d5'), {'role': 'user', 'content': '对于所有回答要翻译成英文、中文、日语三种语言'}]\n",
      "{'mm': [HumanMessage(content='曼波、曼波', additional_kwargs={}, response_metadata={}, id='b835ee54-e0cb-4a50-a781-4bee4fe88a5d'), SystemMessage(content='你是一位网络梗专家，专门帮忙解答网络梗相关的问题。', additional_kwargs={}, response_metadata={}, id='a423b4be-0cf0-4b80-9b39-35b1334161d5'), AIMessage(content='<think>\\n好的，用户发来了“曼波、曼波”，然后要求所有回答翻译成英文、中文、日语三种语言。首先，我需要确认“曼波”指的是什么。可能是指舞蹈“曼波舞”（Mambo），这是一种源自古巴的舞蹈，节奏欢快，动作灵活。也有可能是其他含义，但根据常见网络用语，曼波舞应该是主要的。\\n\\n接下来，用户可能是在测试我的知识库，或者想了解曼波舞的相关信息。需要确保回答准确，同时满足三种语言的要求。另外，用户可能对曼波舞有特别的兴趣，或者想用在某个场合，比如社交、教学等。\\n\\n需要检查是否有其他可能的解释，但根据常见用法，曼波舞是正确的。然后，翻译部分要准确，英文是Mambo，中文是曼波舞，日语是マンボ。然后，回答部分需要涵盖曼波舞的起源、特点、流行情况等，确保信息正确，同时用三种语言表达。\\n\\n另外，用户可能希望得到简洁明了的回答，所以需要分点说明，但用户没有要求分点，所以保持段落形式即可。确保翻译无误，避免误解。最后，确认是否遗漏了其他可能的解释，但暂时没有发现，所以继续按曼波舞来回答。\\n</think>\\n\\n**English:**  \\nMambo is a lively dance originating from Cuba, characterized by its fast rhythm and intricate footwork. It became popular in the 1940s and is often associated with vibrant social events.  \\n\\n**中文：**  \\n曼波是一种源自古巴的活力四溢的舞蹈，以快速的节奏和复杂的脚步动作为特点。它在20世纪40年代广受欢迎，常与热闹的社交活动联系在一起。  \\n\\n**日语：**  \\nマンボはキューバから起源するエネルギッシュなダンスで、速いリズムと複雑な足元の動きが特徴です。1940年代に広く人気となり、活気に満ちた社交イベントと関連付けられます。', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-06-22T12:06:55.881963421Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3833924152, 'load_duration': 9717948, 'prompt_eval_count': 51, 'prompt_eval_duration': 12981270, 'eval_count': 447, 'eval_duration': 3806986905, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run--61193bda-1ec2-4b74-bee7-b39fb3de3529-0', usage_metadata={'input_tokens': 51, 'output_tokens': 447, 'total_tokens': 498})]}\n",
      "<think>\n",
      "好的，用户发来了“曼波、曼波”，然后要求所有回答翻译成英文、中文、日语三种语言。首先，我需要确认“曼波”指的是什么。可能是指舞蹈“曼波舞”（Mambo），这是一种源自古巴的舞蹈，节奏欢快，动作灵活。也有可能是其他含义，但根据常见网络用语，曼波舞应该是主要的。\n",
      "\n",
      "接下来，用户可能是在测试我的知识库，或者想了解曼波舞的相关信息。需要确保回答准确，同时满足三种语言的要求。另外，用户可能对曼波舞有特别的兴趣，或者想用在某个场合，比如社交、教学等。\n",
      "\n",
      "需要检查是否有其他可能的解释，但根据常见用法，曼波舞是正确的。然后，翻译部分要准确，英文是Mambo，中文是曼波舞，日语是マンボ。然后，回答部分需要涵盖曼波舞的起源、特点、流行情况等，确保信息正确，同时用三种语言表达。\n",
      "\n",
      "另外，用户可能希望得到简洁明了的回答，所以需要分点说明，但用户没有要求分点，所以保持段落形式即可。确保翻译无误，避免误解。最后，确认是否遗漏了其他可能的解释，但暂时没有发现，所以继续按曼波舞来回答。\n",
      "</think>\n",
      "\n",
      "**English:**  \n",
      "Mambo is a lively dance originating from Cuba, characterized by its fast rhythm and intricate footwork. It became popular in the 1940s and is often associated with vibrant social events.  \n",
      "\n",
      "**中文：**  \n",
      "曼波是一种源自古巴的活力四溢的舞蹈，以快速的节奏和复杂的脚步动作为特点。它在20世纪40年代广受欢迎，常与热闹的社交活动联系在一起。  \n",
      "\n",
      "**日语：**  \n",
      "マンボはキューバから起源するエネルギッシュなダンスで、速いリズムと複雑な足元の動きが特徴です。1940年代に広く人気となり、活気に満ちた社交イベントと関連付けられます。\n"
     ]
    }
   ],
   "source": [
    "class input_state(TypedDict):\n",
    "    mm: Annotated[list[AnyMessage], add_messages]\n",
    "    # mm: int\n",
    "\n",
    "\n",
    "def node_a(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    prompt = \"你是一位网络梗专家，专门帮忙解答网络梗相关的问题。\"\n",
    "    message = [{\"role\": \"system\", \"content\": prompt}]\n",
    "    return {\"mm\": message}\n",
    "\n",
    "def node_b(input:input_state):\n",
    "    \"\"\"A node that processes the input state.\"\"\"\n",
    "    messages = input[\"mm\"] + [{\"role\": \"user\", \"content\": \"对于所有回答要翻译成英文、中文、日语三种语言\"}]\n",
    "    answer = llm.invoke(messages)\n",
    "    print(messages)\n",
    "\n",
    "    return {\"mm\": answer}\n",
    "\n",
    "graph = StateGraph(input_state)\n",
    "\n",
    "graph.add_node(\"node_a\", node_a)\n",
    "graph.add_node(\"node_b\", node_b)\n",
    "\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_edge(\"node_a\", \"node_b\")\n",
    "graph.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "answer = graph.invoke({\"mm\": [HumanMessage(content=\"曼波、曼波\")]})\n",
    "print(answer)\n",
    "print(answer[\"mm\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43f451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
