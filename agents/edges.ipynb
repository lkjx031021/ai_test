{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "695f2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from yaml import safe_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e759d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_process(message):\n",
    "    # Process the message after the LLM response\n",
    "    mm = message.content\n",
    "    mm = re.sub(r'<think>.*?</think>', '', mm, flags=re.DOTALL).strip()  # Remove <think> tags\n",
    "    return mm\n",
    "\n",
    "os.environ['openai_api_key'] = \"\"  # Replace with your actual OpenAI API key\n",
    "cfg = safe_load(open(\"../settings.yaml\", \"r\"))\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", base_url='https://api.deepseek.com/v1')\n",
    "# llm = ChatOllama(model=cfg[\"test_model_name\"])\n",
    "# llm = llm | after_process\n",
    "\n",
    "# llm = prompt | llm# | after_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e046c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.  \\n\\nParis is known for its iconic landmarks such as the **Eiffel Tower**, **Louvre Museum**, and **Notre-Dame Cathedral**, as well as its rich history, art, and culture.  \\n\\nWould you like recommendations for things to do in Paris? ğŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 10, 'total_tokens': 75, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 10}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '8e3f4beb-456f-4ec8-bf5a-cb4d3c911c13', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5fada6fa-c439-41b4-a7c9-1e20d9d2e76e-0', usage_metadata={'input_tokens': 10, 'output_tokens': 65, 'total_tokens': 75, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "818ed3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(binal_response=CustomerInfo(user_id='83729', hhh='84739', order_number='1025NM248AWi', order_price=99.99, order_num=3))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Union, Optional\n",
    "\n",
    "class UserInput(BaseModel):\n",
    "    name: str = Field(..., description=\"The user's input question or request.\")\n",
    "    age: Optional[int] = Field(None, description=\"Optional age of the user.\")\n",
    "    email: Optional[str] = Field(None, description=\"Optional email of the user.\")\n",
    "    phone: Optional[str] = Field(None, description=\"Optional phone number of the user.\")\n",
    "\n",
    "class CustomerInfo(BaseModel):\n",
    "    user_id: str = Field(..., description=\"user_id\")\n",
    "    hhh: str = Field(..., description=\"order_id\")\n",
    "    order_number: str = Field(..., description=\"è®¢å•ç¼–å·\")\n",
    "    order_price: float = Field(..., description=\"è®¢å•ä»·æ ¼\")\n",
    "    order_num: int = Field(..., description=\"ä¸‹å•æ¬¡æ•°\", ge=0)\n",
    "\n",
    "class ConversationResponse(BaseModel):\n",
    "    response: str = Field(..., description=\"The response generated by the assistant.\")\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    binal_response: Union[ConversationResponse, CustomerInfo, UserInput]\n",
    "    \n",
    "\n",
    "llm_s = llm.with_structured_output(FinalResponse)\n",
    "\n",
    "# res = llm_s.invoke('my name is John, I am 30 years old, my email is 222@163.com, my phone is 1234567890')\n",
    "# res = llm_s.invoke('ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ')  # This will return a structured response\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # SystemMessage(content=\"ä½ ä¸“é—¨è´Ÿè´£ä»è‡ªç„¶è¯­è¨€ä¸­æå–ç»“æ„åŒ–ä¿¡\"),\n",
    "#     SystemMessage(content=\"\"\"\n",
    "#         æ•°æ®å­—å…¸:\n",
    "#             user_id: ç”¨æˆ·ID\n",
    "#             hhh: è®¢å•ID ç”±çº¯æ•°å­—ç»„æˆ,é€šå¸¸æ˜¯5ä½æ•°å­—ç»„æˆ\n",
    "#             order_number: è®¢å•ç¼–å· åŒ…å«å­—æ¯å’Œæ•°å­— é€šå¸¸åœ¨8ä½ä»¥ä¸Š\n",
    "#             order_price: è®¢å•ä»·æ ¼\n",
    "#             order_num: ä¸‹å•æ¬¡æ•° 0æˆ–æ­£æ•´æ•°\n",
    "#         e.g:\n",
    "#         ç”¨æˆ·è¾“å…¥ä¸º \"ç”¨æˆ·IDæ˜¯ 12345, è®¢å•ç¼–å·æ˜¯2938NM229AWiï¼Œè®¢å•id: 67890, è®¢å•ä»·æ ¼: 23.098, ä¸‹å•æ¬¡æ•°: 15\n",
    "#         ç»“æ„åŒ–ä¿¡æ¯ä¸ºï¼šï¼š\n",
    "#         {\n",
    "#             \"user_id\": \"12345\",\n",
    "#             \"hhh\": \"67890\",\n",
    "#             \"order_number\": \"2938NM229AWi\",\n",
    "#             \"order_price\": 23.098,\n",
    "#             \"order_num\": 15\n",
    "#         # }\n",
    "# \"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "llm_query = prompt | llm_s\n",
    "res = llm_query.invoke({\"input\":\"ç”¨æˆ·IDæ˜¯ 83729, è®¢å•ç¼–å·æ˜¯1025NM248AWiï¼Œè®¢å•id: 84739, è®¢å•ä»·æ ¼: 99.99, ä¸‹å•æ¬¡æ•°: 3\"})\n",
    "# res = llm_s.invoke(\"user_idæ˜¯ 12345, è®¢å•ç¼–å·æ˜¯2938NM229AWiï¼Œè®¢å•id: 67890, è®¢å•ä»·æ ¼: 99.99, ä¸‹å•æ¬¡æ•°: 3\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fcc2b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binal_response=ConversationResponse(response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.')\n",
      "------\n",
      "00000000000000000000\n",
      "{'input': [HumanMessage(content='what is DeepLearning', additional_kwargs={}, response_metadata={}), FinalResponse(binal_response=ConversationResponse(response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.'))]}\n",
      "<class '__main__.FinalResponse'>\n",
      "response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.'\n",
      "<class '__main__.ConversationResponse'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': [HumanMessage(content='what is DeepLearning', additional_kwargs={}, response_metadata={}),\n",
       "  FinalResponse(binal_response=ConversationResponse(response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.'))]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "from typing import TypedDict\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData\n",
    "from torch import Type\n",
    "from utils import save_graph\n",
    "\n",
    "DATABASE_URI = 'mysql+pymysql://root:sonw1234567!@127.0.0.1/langgraph_agent?charset=utf8mb4'   \n",
    "engine = create_engine(DATABASE_URI, echo=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String(50))\n",
    "    age = Column(Integer)\n",
    "    email = Column(String(100))\n",
    "    phone = Column(String(15))\n",
    "\n",
    "def insert_db(state):\n",
    "    print(state)\n",
    "    message = state[\"input\"][-1].binal_response\n",
    "    session = Session()\n",
    "\n",
    "    try:\n",
    "        user = User(name=message.name, age=message.age, email=message.email, phone=message.phone)\n",
    "        session.add(user)\n",
    "        session.commit()\n",
    "        return {\"input\": [AIMessage(content=\"User information has been saved successfully.\")]}\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "def chat_bot(state):\n",
    "    user_input = state[\"input\"]\n",
    "    response = llm_s.invoke(user_input)\n",
    "    print(response)\n",
    "    print('------')\n",
    "    return {\"input\": [response]}\n",
    "    \n",
    "def conditional_(state):\n",
    "    print('00000000000000000000')\n",
    "    print(state)\n",
    "    print(type(state[\"input\"][-1]))\n",
    "    output = state[\"input\"][-1].binal_response\n",
    "    print(output)\n",
    "    print(type(output))\n",
    "    # if isinstance(output, ConversationResponse):\n",
    "        # return  True\n",
    "    # if isinstance(output, UserInput):\n",
    "        # return False\n",
    "    if isinstance(output, UserInput):\n",
    "        return \"insert_db\"\n",
    "    if isinstance(output, ConversationResponse):\n",
    "        return  \"final_answer\"\n",
    "\n",
    "def final_answer(state):\n",
    "    output = state[\"input\"][-1].binal_response.response\n",
    "    return {\"final_answer\": output}\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chat_bot\", chat_bot)\n",
    "builder.add_node(\"insert_db\", insert_db)\n",
    "builder.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "builder.set_entry_point(\"chat_bot\")\n",
    "builder.add_conditional_edges(\"chat_bot\", conditional_)\n",
    "\n",
    "builder.set_finish_point(\"final_answer\")\n",
    "builder.set_finish_point(\"insert_db\")\n",
    "\n",
    "builder = builder.compile()\n",
    "save_graph(builder, \"graph_single_agent.png\")\n",
    "\n",
    "# builder.invoke({\"input\": [HumanMessage(\"my name is John, I am 30 years old, my email is 222@163.com, my phone is 1234567890\")]})\n",
    "builder.invoke({\"input\": [HumanMessage(\"what is DeepLearning\")],})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
