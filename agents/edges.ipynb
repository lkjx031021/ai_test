{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "695f2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from yaml import safe_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e759d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_process(message):\n",
    "    # Process the message after the LLM response\n",
    "    mm = message.content\n",
    "    mm = re.sub(r'<think>.*?</think>', '', mm, flags=re.DOTALL).strip()  # Remove <think> tags\n",
    "    return mm\n",
    "\n",
    "os.environ['openai_api_key'] = \"\"  # Replace with your actual OpenAI API key\n",
    "cfg = safe_load(open(\"../settings.yaml\", \"r\"))\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", base_url='https://api.deepseek.com/v1')\n",
    "# llm = ChatOllama(model=cfg[\"test_model_name\"])\n",
    "# llm = llm | after_process\n",
    "\n",
    "# llm = prompt | llm# | after_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e046c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.  \\n\\nParis is known for its iconic landmarks such as the **Eiffel Tower**, **Louvre Museum**, and **Notre-Dame Cathedral**, as well as its rich history, art, and culture.  \\n\\nWould you like recommendations for things to do in Paris? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 10, 'total_tokens': 75, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 10}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '8e3f4beb-456f-4ec8-bf5a-cb4d3c911c13', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5fada6fa-c439-41b4-a7c9-1e20d9d2e76e-0', usage_metadata={'input_tokens': 10, 'output_tokens': 65, 'total_tokens': 75, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "818ed3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(binal_response=CustomerInfo(user_id='83729', hhh='84739', order_number='1025NM248AWi', order_price=99.99, order_num=3))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Union, Optional\n",
    "\n",
    "class UserInput(BaseModel):\n",
    "    name: str = Field(..., description=\"The user's input question or request.\")\n",
    "    age: Optional[int] = Field(None, description=\"Optional age of the user.\")\n",
    "    email: Optional[str] = Field(None, description=\"Optional email of the user.\")\n",
    "    phone: Optional[str] = Field(None, description=\"Optional phone number of the user.\")\n",
    "\n",
    "class CustomerInfo(BaseModel):\n",
    "    user_id: str = Field(..., description=\"user_id\")\n",
    "    hhh: str = Field(..., description=\"order_id\")\n",
    "    order_number: str = Field(..., description=\"订单编号\")\n",
    "    order_price: float = Field(..., description=\"订单价格\")\n",
    "    order_num: int = Field(..., description=\"下单次数\", ge=0)\n",
    "\n",
    "class ConversationResponse(BaseModel):\n",
    "    response: str = Field(..., description=\"The response generated by the assistant.\")\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    binal_response: Union[ConversationResponse, CustomerInfo, UserInput]\n",
    "    \n",
    "\n",
    "llm_s = llm.with_structured_output(FinalResponse)\n",
    "\n",
    "# res = llm_s.invoke('my name is John, I am 30 years old, my email is 222@163.com, my phone is 1234567890')\n",
    "# res = llm_s.invoke('什么是深度学习')  # This will return a structured response\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # SystemMessage(content=\"你专门负责从自然语言中提取结构化信\"),\n",
    "#     SystemMessage(content=\"\"\"\n",
    "#         数据字典:\n",
    "#             user_id: 用户ID\n",
    "#             hhh: 订单ID 由纯数字组成,通常是5位数字组成\n",
    "#             order_number: 订单编号 包含字母和数字 通常在8位以上\n",
    "#             order_price: 订单价格\n",
    "#             order_num: 下单次数 0或正整数\n",
    "#         e.g:\n",
    "#         用户输入为 \"用户ID是 12345, 订单编号是2938NM229AWi，订单id: 67890, 订单价格: 23.098, 下单次数: 15\n",
    "#         结构化信息为：：\n",
    "#         {\n",
    "#             \"user_id\": \"12345\",\n",
    "#             \"hhh\": \"67890\",\n",
    "#             \"order_number\": \"2938NM229AWi\",\n",
    "#             \"order_price\": 23.098,\n",
    "#             \"order_num\": 15\n",
    "#         # }\n",
    "# \"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "llm_query = prompt | llm_s\n",
    "res = llm_query.invoke({\"input\":\"用户ID是 83729, 订单编号是1025NM248AWi，订单id: 84739, 订单价格: 99.99, 下单次数: 3\"})\n",
    "# res = llm_s.invoke(\"user_id是 12345, 订单编号是2938NM229AWi，订单id: 67890, 订单价格: 99.99, 下单次数: 3\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fcc2b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binal_response=ConversationResponse(response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.')\n",
      "------\n",
      "00000000000000000000\n",
      "{'input': [HumanMessage(content='what is DeepLearning', additional_kwargs={}, response_metadata={}), FinalResponse(binal_response=ConversationResponse(response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.'))]}\n",
      "<class '__main__.FinalResponse'>\n",
      "response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.'\n",
      "<class '__main__.ConversationResponse'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': [HumanMessage(content='what is DeepLearning', additional_kwargs={}, response_metadata={}),\n",
       "  FinalResponse(binal_response=ConversationResponse(response='Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn and make decisions. It is particularly effective for tasks such as image recognition, natural language processing, and speech recognition. Deep learning models are trained on large amounts of data, allowing them to identify patterns and make predictions with high accuracy. The key advantage of deep learning is its ability to automatically learn features from raw data, which reduces the need for manual feature engineering. However, deep learning models can be computationally intensive and require a lot of data to train effectively. They are widely used in industries such as healthcare, finance, and autonomous vehicles.'))]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "from typing import TypedDict\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData\n",
    "from torch import Type\n",
    "from utils import save_graph\n",
    "\n",
    "DATABASE_URI = 'mysql+pymysql://root:sonw1234567!@127.0.0.1/langgraph_agent?charset=utf8mb4'   \n",
    "engine = create_engine(DATABASE_URI, echo=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String(50))\n",
    "    age = Column(Integer)\n",
    "    email = Column(String(100))\n",
    "    phone = Column(String(15))\n",
    "\n",
    "def insert_db(state):\n",
    "    print(state)\n",
    "    message = state[\"input\"][-1].binal_response\n",
    "    session = Session()\n",
    "\n",
    "    try:\n",
    "        user = User(name=message.name, age=message.age, email=message.email, phone=message.phone)\n",
    "        session.add(user)\n",
    "        session.commit()\n",
    "        return {\"input\": [AIMessage(content=\"User information has been saved successfully.\")]}\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "def chat_bot(state):\n",
    "    user_input = state[\"input\"]\n",
    "    response = llm_s.invoke(user_input)\n",
    "    print(response)\n",
    "    print('------')\n",
    "    return {\"input\": [response]}\n",
    "    \n",
    "def conditional_(state):\n",
    "    print('00000000000000000000')\n",
    "    print(state)\n",
    "    print(type(state[\"input\"][-1]))\n",
    "    output = state[\"input\"][-1].binal_response\n",
    "    print(output)\n",
    "    print(type(output))\n",
    "    # if isinstance(output, ConversationResponse):\n",
    "        # return  True\n",
    "    # if isinstance(output, UserInput):\n",
    "        # return False\n",
    "    if isinstance(output, UserInput):\n",
    "        return \"insert_db\"\n",
    "    if isinstance(output, ConversationResponse):\n",
    "        return  \"final_answer\"\n",
    "\n",
    "def final_answer(state):\n",
    "    output = state[\"input\"][-1].binal_response.response\n",
    "    return {\"final_answer\": output}\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chat_bot\", chat_bot)\n",
    "builder.add_node(\"insert_db\", insert_db)\n",
    "builder.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "builder.set_entry_point(\"chat_bot\")\n",
    "builder.add_conditional_edges(\"chat_bot\", conditional_)\n",
    "\n",
    "builder.set_finish_point(\"final_answer\")\n",
    "builder.set_finish_point(\"insert_db\")\n",
    "\n",
    "builder = builder.compile()\n",
    "save_graph(builder, \"graph_single_agent.png\")\n",
    "\n",
    "# builder.invoke({\"input\": [HumanMessage(\"my name is John, I am 30 years old, my email is 222@163.com, my phone is 1234567890\")]})\n",
    "builder.invoke({\"input\": [HumanMessage(\"what is DeepLearning\")],})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
